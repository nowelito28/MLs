{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 2. Tema 5. Búsqueda de hiperparámetros en ML.\n",
    "Aplicar hiperparámetros externos a los modelos de ML para alcanzar una predicción mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../datasets/south_africa_chd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape\n",
    "data_df.head()\n",
    "ohe_famhist = OneHotEncoder(drop='if_binary').fit_transform(data_df[['famhist']])\n",
    "data_df['famhist'] = ohe_famhist.toarray()\n",
    "ohe_chd = OneHotEncoder(drop='if_binary').fit_transform(data_df[['chd']])\n",
    "data_df['chd'] = ohe_chd.toarray()\n",
    "data_df.head()\n",
    "data = data_df.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en conjuntos de entrenamiento, validación y prueba:\n",
    "- Traning set -> 60% de los datos\n",
    "- Validation set -> 20% de los datos\n",
    "- Test set -> 20% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:-1]\n",
    "Y = data[:,-1]\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.4, random_state=42, stratify=Y)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42, stratify=Y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar las características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicamos validación cruzada con K-fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal -> Método de regresión ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Búsqueda de hiperparámetros para regresión lineal usando GridSearchCV:\n",
    "- Grid Search: Se define un rango o conjunto de valores posibles para cada hiperparámetro, y el método prueba todas las combinaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Regresión Lineal (GridSearchCV): {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': True}\n",
      "Mejor score de validación (GridSearchCV) para regresión lineal: -0.19098900727769477\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'fit_intercept': [True, False],       # Incluir o no el intercepto\n",
    "    'copy_X': [True, False],              # Copiar X antes de ajustar\n",
    "    'n_jobs': [-1, 1],                    # Número de trabajos para paralelización\n",
    "    'positive': [True, False]             # Forzar los coeficientes a ser no negativos\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(LinearRegression(), param_grid_lr, cv=kf, scoring='neg_mean_squared_error')\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Mejores parámetros para Regresión Lineal (GridSearchCV):\", grid_search_lr.best_params_)\n",
    "print(\"Mejor score de validación (GridSearchCV) para regresión lineal:\", grid_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones y evaluaciones de la Regresión Lineal con Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (GridSearchCV): 0.16600652404354585, R2 (GridSearchCV): 0.26445162579271075\n"
     ]
    }
   ],
   "source": [
    "Y_pred_lr1 = grid_search_lr.predict(X_test)\n",
    "# Error cuadrático medio -> Error, en media, cuadrático de las predicciones frente a valores observados\n",
    "mse_lr = mean_squared_error(Y_test, Y_pred_lr1)\n",
    "# Coeficiente de determinación -> Variabilidad de las variables a predecir, (entre 0: NO puede predecir, y 1: predice perfectamente)\n",
    "r2_lr = r2_score(Y_test, Y_pred_lr1) \n",
    "print(f'MSE (GridSearchCV): {mse_lr}, R2 (GridSearchCV): {r2_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo comparamos con los resultados obtenidos en la anterior práctica, podemos ver que obtenemos resultados mejores. Con un error cuadrático medio menor, indicando que se comete menos errores a la hora de predecir; y un coeficiente de determinación algo mayor, pero sigue estando bastante alejado de la unidad para poder concluir que se realiza una predicción de forma correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Búsqueda de hiperparámetros para Regresión Lineal con RandomizedSearchCV:\n",
    "- Random Search: En lugar de probar todas las combinaciones posibles (como en Grid Search), selecciona un número fijo de combinaciones aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Regresión Lineal (GridSearchCV): {'positive': True, 'n_jobs': -1, 'fit_intercept': True, 'copy_X': True}\n",
      "Mejor score de validación (GridSearchCV) para regresión lineal: -0.19098900727769477\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'fit_intercept': [True, False],       # Incluir o no el intercepto\n",
    "    'copy_X': [True, False],              # Copiar X antes de ajustar\n",
    "    'n_jobs': [-1, 1],                    # Número de trabajos para paralelización\n",
    "    'positive': [True, False]             # Forzar los coeficientes a ser no negativos\n",
    "}\n",
    "\n",
    "random_search_lr = RandomizedSearchCV(LinearRegression(), param_grid_lr, cv=kf, scoring='neg_mean_squared_error')\n",
    "random_search_lr.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Mejores parámetros para Regresión Lineal (GridSearchCV):\", random_search_lr.best_params_)\n",
    "print(\"Mejor score de validación (GridSearchCV) para regresión lineal:\", random_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones y evaluciones de la Regresión Lineal con Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (GridSearchCV): 0.16600652404354585, R2 (GridSearchCV): 0.26445162579271075\n"
     ]
    }
   ],
   "source": [
    "Y_pred_lr2 = random_search_lr.predict(X_test)\n",
    "# Error cuadrático medio -> Error, en media, cuadrático de las predicciones frente a valores observados\n",
    "mse_lr = mean_squared_error(Y_test, Y_pred_lr2)\n",
    "# Coeficiente de determinación -> Variabilidad de las variables a predecir, (entre 0: NO puede predecir, y 1: predice perfectamente)\n",
    "r2_lr = r2_score(Y_test, Y_pred_lr2) \n",
    "print(f'MSE (GridSearchCV): {mse_lr}, R2 (GridSearchCV): {r2_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos mediante este método, los mismos resultados que en el método anterior, pero podríamos haber obtenido un resultado ligeramente peor. Ya que en este caso, no evaluamos todas las combinaciones como en Grid Search, sino un número de combinaciones fijas al azar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística -> Método de clasificación ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Búsqueda de hiperparámetros para Regresión Logística usando GridSearchCV:\n",
    "- Grid Search: Se define un rango o conjunto de valores posibles para cada hiperparámetro, y el método prueba todas las combinaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Mejores parámetros para Regresión Logística (GridSearchCV): {'C': 0.1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Mejor score de validación (GridSearchCV) para regresión logística: 0.725844155844156\n"
     ]
    }
   ],
   "source": [
    "param_grid_logr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],                        # Valores de C para regularización\n",
    "    'solver': ['liblinear', 'saga', 'newton-cg', 'lbfgs'],      # Solvers disponibles\n",
    "    'max_iter': [100, 200, 300, 500],                           # Número de iteraciones\n",
    "}\n",
    "\n",
    "grid_search_logr = GridSearchCV(LogisticRegression(), param_grid_logr, cv=kf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search_logr.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Mejores parámetros para Regresión Logística (GridSearchCV):\", grid_search_logr.best_params_)\n",
    "print(\"Mejor score de validación (GridSearchCV) para regresión logística:\", grid_search_logr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones y evaluaciones de la Regresión Logística con Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7204\n",
      "Matriz de Confusión:\n",
      "[[49 12]\n",
      " [14 18]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred1 = grid_search_logr.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "accuracy1 = accuracy_score(Y_test, Y_pred1)\n",
    "conf_matrix1 = confusion_matrix(Y_test, Y_pred1)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Accuracy: {accuracy1:.4f}\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Búsqueda de hiperparámetros para Regresión Logística con RandomizedSearchCV:\n",
    "- Random Search: En lugar de probar todas las combinaciones posibles (como en Grid Search), selecciona un número fijo de combinaciones aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Regresión Logística (RandomizedSearchCV): {'C': 54.88235039273247, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "Mejor score de validación (RandomizedSearchCV) para regresión logística: 0.7005194805194807\n"
     ]
    }
   ],
   "source": [
    "param_dist_lr = {\n",
    "    'C': uniform(0.001, 100),                               # Regularización\n",
    "    'solver': ['liblinear', 'saga', 'newton-cg', 'lbfgs'],  # Solvers disponibles\n",
    "    'max_iter': [300, 500, 1000],                           # Número máximo de iteraciones\n",
    "}\n",
    "\n",
    "random_search_logr = RandomizedSearchCV(LogisticRegression(), param_dist_lr, n_iter=100, cv=kf, scoring='accuracy', random_state=0)\n",
    "random_search_logr.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Mejores parámetros para Regresión Logística (RandomizedSearchCV):\", random_search_logr.best_params_)\n",
    "print(\"Mejor score de validación (RandomizedSearchCV) para regresión logística:\", random_search_logr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones y evaluciones de la Regresión Logística con Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7204\n",
      "Matriz de Confusión:\n",
      "[[48 13]\n",
      " [13 19]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred2 = random_search_logr.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "accuracy2 = accuracy_score(Y_test, Y_pred2)\n",
    "conf_matrix2 = confusion_matrix(Y_test, Y_pred2)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Accuracy: {accuracy2:.4f}\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el método de ML de Regresión Logóstica, con ambos métodos de obtención de hiperparámetros, obtenemos los mismos resultados; los cuales no llegan a mejorar el anterior modelo sin hiperparámetros. Esto puede ser debido a la poca densidad de datos que tenemos, ya que se generar patrones distintos que antes y podría afectar a una clase concreta más que a otra, por lo que se podría ver mejoría con mucho mayor volumen de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
